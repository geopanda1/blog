[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "LWD Tirol Meteo Download Package\n\n\n\n\n\n\n\npython-package\n\n\ndata-download\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2025\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nGeosphere Download Package\n\n\n\n\n\n\n\npython-package\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "code-snippets.html",
    "href": "code-snippets.html",
    "title": "Code snippets",
    "section": "",
    "text": "Various pieces of code I regularily use."
  },
  {
    "objectID": "code-snippets/dask/00_local-cluster.html",
    "href": "code-snippets/dask/00_local-cluster.html",
    "title": "Local cluster",
    "section": "",
    "text": "How to setup a local dask cluster.\nfor i in range(10):\n    print(i)"
  },
  {
    "objectID": "code-snippets/sqlalchemy/00_relations.html",
    "href": "code-snippets/sqlalchemy/00_relations.html",
    "title": "Relations",
    "section": "",
    "text": "How do define relationships without explicitly setting foreign keys.\n\nimport sqlalchemy as db\n\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import declarative_base, relationship, Session\nBase = declarative_base()\n\n\nclass User(Base):\n    __tablename__ = \"user\"\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String)\n    products = relationship(\"Product\", back_populates=\"user\")\n\nclass Product(Base):\n    __tablename__ = \"product\"\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String)\n    user_id = db.Column(db.Integer, db.ForeignKey(\"user.id\"), nullable=False)\n    user = relationship(\"User\", back_populates=\"products\")\n\n\ndb_path = \"sqlite:///test.db\"\nengine = db.create_engine(db_path)\nBase.metadata.create_all(engine, checkfirst=True)\n\nsession = Session(bind=engine)\n# enforce foreign key constraint in SQLite (off by default!)\nsession.execute(text(\"PRAGMA foreign_keys=on\"));\n\n\nuser = User(name=\"Alice\")\nproduct1 = Product(name=\"A\", user=user)\nproduct2 = Product(name=\"B\", user=user)\n\nsession.add(user)\nsession.commit()\n\nForeign key will be correctly assigned by sqlalchemy:\n\nproduct1.user_id\n\n1\n\n\nWorks also the other way round:\n\nuser = User(name=\"Kyle\")\nproduct3 = Product(name=\"A\")\nproduct4 = Product(name=\"B\")\n\nuser.products = [product3, product4]\n\nsession.add(user)\nsession.commit()\n\nForeign key will be correctly assigned by sqlalchemy:\n\nproduct3.user_id\n\n2\n\n\n\nThis does not work\nThe associated user.id will not be set correctly. It will be set to None which is the current value of user.id prior to committing.\n\nuser = User(name=\"Dave\")\n\nproduct5 = Product(name=\"C\", user_id=user.id) # user.id is None at this point!\nproduct6 = Product(name=\"D\", user_id=user.id)\n\nsession.add_all([user, product5, product6])\nsession.commit()\n\nIntegrityError: (sqlite3.IntegrityError) NOT NULL constraint failed: product.user_id\n[SQL: INSERT INTO product (name, user_id) VALUES (?, ?) RETURNING id]\n[parameters: ('C', None)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
  },
  {
    "objectID": "code-snippets/sqlalchemy/01_views.html",
    "href": "code-snippets/sqlalchemy/01_views.html",
    "title": "View with model",
    "section": "",
    "text": "How do create a view with a proper model. tbc"
  },
  {
    "objectID": "code-snippets/xarray/00_stack.html",
    "href": "code-snippets/xarray/00_stack.html",
    "title": "Stack (reshape)",
    "section": "",
    "text": "How to reshape a multidimensional xarray object.\nimport xarray as xr\n\nds = xr.Dataset(...)\n\n\nds_flat = ds.stack(sample=(\"x\", \"y\"))"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\nfor i in range(10):\n    print(i)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/geosphere-download/index.html",
    "href": "posts/geosphere-download/index.html",
    "title": "LWD Tirol Meteo Download Package",
    "section": "",
    "text": "This package is meant to facilitate download meteorological data from the Geosphere (formerly ZAMG) Austria data hub.\nPackage link\n\nfrom pathlib import Path\nimport os\n\n\nprint(os.system(\"python --version\"))\n\nPython 3.13.1\n0"
  },
  {
    "objectID": "posts/new-post/other.html",
    "href": "posts/new-post/other.html",
    "title": "Geosphere Download Package",
    "section": "",
    "text": "Download package for station data from geosphere austria\nfor i in range(10):\n    print(i)"
  },
  {
    "objectID": "code-snippets/dask/00_local_cluster.html",
    "href": "code-snippets/dask/00_local_cluster.html",
    "title": "Local cluster",
    "section": "",
    "text": "import multiprocessing\nfrom dask.distributed import Client, LocalCluster"
  },
  {
    "objectID": "code-snippets/dask/00_local_cluster.html#setup-up-local-dask-cluster",
    "href": "code-snippets/dask/00_local_cluster.html#setup-up-local-dask-cluster",
    "title": "Local cluster",
    "section": "Setup up local dask cluster",
    "text": "Setup up local dask cluster\n\npossibly adjust number of threads per worker\ndon’t forget to put the Client(...) in a if __name__ == \"__main__\" context when running from a script\n\n\nn_workers = multiprocessing.cpu_count()\n\nmem_buffer = 10 # how much memory will be spared from workers\n\ngb_total = 128 # total memory of machine\ngb_available = gb_total - mem_buffer # what is left for dask\ngb_per_worker = int(gb_total / n_workers) # memory for each dask worker\n\n\nclient = Client(\n    address=LocalCluster(\n        n_workers=n_workers,\n        threads_per_worker=2,\n        interface=\"lo\",\n        memory_limit=f\"{gb_per_worker}GB\",\n    )\n)\n\nInspect link to view dashboard\n\nprint(client.dashboard_link)\n\nhttp://127.0.0.1:8787/status"
  },
  {
    "objectID": "code-snippets/xarray/03_resampling_rioxarray.html",
    "href": "code-snippets/xarray/03_resampling_rioxarray.html",
    "title": "Resampling rioxarray",
    "section": "",
    "text": "tbc"
  },
  {
    "objectID": "code-snippets/xarray/00_rf_predict_apply_ufunc.html",
    "href": "code-snippets/xarray/00_rf_predict_apply_ufunc.html",
    "title": "xr.apply_ufunc(…)",
    "section": "",
    "text": "Note: ds.map_blocks() likely is a lot faster compared to this version! This is really only for demonstrative purpose.\n\nimport dask.array as da\nimport xarray as xr\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier as RF\n\n\nn_features = 12\n\n\nn_samples = 1000\n# random training data\nX_train = da.random.random((n_samples,n_features))\ny_train = da.random.randint(0, 2, n_samples)\n\nrf = RF(random_state = 42, n_estimators=50, n_jobs=-1)\nrf.fit(X_train, y_train)\n\nRandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42) \n\n\n\n# random training data\n# keep size reasonably small\nlat = np.arange(40)\nlon = np.arange(60)\ntime = np.arange(n_features)\ndata = da.random.random((lat.size,lon.size, time.size))\n\n\nds = xr.DataArray(\n    data,\n    coords=[lat, lon, time],\n    dims=[\"lat\", \"lon\", \"time\"],\n    name=\"test\",\n).to_dataset()\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 231kB\nDimensions:  (lat: 40, lon: 60, time: 12)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\n  * time     (time) int64 96B 0 1 2 3 4 5 6 7 8 9 10 11\nData variables:\n    test     (lat, lon, time) float64 230kB dask.array<chunksize=(40, 60, 12), meta=np.ndarray>xarray.DatasetDimensions:lat: 40lon: 60time: 12Coordinates: (3)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])time(time)int640 1 2 3 4 5 6 7 8 9 10 11array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])Data variables: (1)test(lat, lon, time)float64dask.array<chunksize=(40, 60, 12), meta=np.ndarray>\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         225.00 kiB \n                         225.00 kiB \n                    \n                    \n                    \n                         Shape \n                         (40, 60, 12) \n                         (40, 60, 12) \n                    \n                    \n                         Dask graph \n                         1 chunks in 1 graph layer \n                    \n                    \n                         Data type \n                         float64 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  12\n  60\n  40\n\n        \n    \nIndexes: (3)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))timePandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype='int64', name='time'))Attributes: (0)\n\n\n\ndef generic_func(arr):\n    return rf.predict(arr.reshape(1, -1))\n\n\nds_ag = xr.apply_ufunc(\n    generic_func,\n    ds,\n    input_core_dims=[[\"time\"]],\n    dask=\"parallelized\",\n    output_dtypes=np.float32,\n    vectorize=True,\n    dask_gufunc_kwargs={\"allow_rechunk\": True},\n)\n\n\nds_ag\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 10kB\nDimensions:  (lat: 40, lon: 60)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\nData variables:\n    test     (lat, lon) float32 10kB dask.array<chunksize=(40, 60), meta=np.ndarray>xarray.DatasetDimensions:lat: 40lon: 60Coordinates: (2)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])Data variables: (1)test(lat, lon)float32dask.array<chunksize=(40, 60), meta=np.ndarray>\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         9.38 kiB \n                         9.38 kiB \n                    \n                    \n                    \n                         Shape \n                         (40, 60) \n                         (40, 60) \n                    \n                    \n                         Dask graph \n                         1 chunks in 4 graph layers \n                    \n                    \n                         Data type \n                         float32 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  60\n  40\n\n        \n    \nIndexes: (2)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))Attributes: (0)\n\n\n\nds_ag.compute()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 10kB\nDimensions:  (lat: 40, lon: 60)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\nData variables:\n    test     (lat, lon) float32 10kB 0.0 1.0 1.0 0.0 0.0 ... 1.0 1.0 1.0 1.0 1.0xarray.DatasetDimensions:lat: 40lon: 60Coordinates: (2)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])Data variables: (1)test(lat, lon)float320.0 1.0 1.0 0.0 ... 1.0 1.0 1.0 1.0array([[0., 1., 1., ..., 1., 0., 1.],\n       [1., 0., 0., ..., 1., 0., 0.],\n       [0., 1., 1., ..., 0., 1., 0.],\n       ...,\n       [0., 0., 1., ..., 0., 1., 1.],\n       [1., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]], shape=(40, 60), dtype=float32)Indexes: (2)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))Attributes: (0)"
  },
  {
    "objectID": "code-snippets/xarray/02_resample_custom_func.html",
    "href": "code-snippets/xarray/02_resample_custom_func.html",
    "title": "Temporal resampling/aggregation",
    "section": "",
    "text": "import xarray as xr\nimport numpy as np\nimport pandas as pd\n\n\n# random training data\nlat = np.arange(40)\nlon = np.arange(60)\ntime = pd.date_range(\"2021-01-01\", \"2021-04-30\", freq=\"1D\")\ndata = np.random.random((lat.size, lon.size, time.size))\n\n\nds = xr.DataArray(\n    data,\n    coords=[lat, lon, time],\n    dims=[\"lat\", \"lon\", \"time\"],\n    name=\"test\",\n).to_dataset()\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 2MB\nDimensions:  (lat: 40, lon: 60, time: 120)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\n  * time     (time) datetime64[ns] 960B 2021-01-01 2021-01-02 ... 2021-04-30\nData variables:\n    test     (lat, lon, time) float64 2MB 0.776 0.7811 0.4746 ... 0.1644 0.4596xarray.DatasetDimensions:lat: 40lon: 60time: 120Coordinates: (3)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])time(time)datetime64[ns]2021-01-01 ... 2021-04-30array(['2021-01-01T00:00:00.000000000', '2021-01-02T00:00:00.000000000',\n       '2021-01-03T00:00:00.000000000', '2021-01-04T00:00:00.000000000',\n       '2021-01-05T00:00:00.000000000', '2021-01-06T00:00:00.000000000',\n       '2021-01-07T00:00:00.000000000', '2021-01-08T00:00:00.000000000',\n       '2021-01-09T00:00:00.000000000', '2021-01-10T00:00:00.000000000',\n       '2021-01-11T00:00:00.000000000', '2021-01-12T00:00:00.000000000',\n       '2021-01-13T00:00:00.000000000', '2021-01-14T00:00:00.000000000',\n       '2021-01-15T00:00:00.000000000', '2021-01-16T00:00:00.000000000',\n       '2021-01-17T00:00:00.000000000', '2021-01-18T00:00:00.000000000',\n       '2021-01-19T00:00:00.000000000', '2021-01-20T00:00:00.000000000',\n       '2021-01-21T00:00:00.000000000', '2021-01-22T00:00:00.000000000',\n       '2021-01-23T00:00:00.000000000', '2021-01-24T00:00:00.000000000',\n       '2021-01-25T00:00:00.000000000', '2021-01-26T00:00:00.000000000',\n       '2021-01-27T00:00:00.000000000', '2021-01-28T00:00:00.000000000',\n       '2021-01-29T00:00:00.000000000', '2021-01-30T00:00:00.000000000',\n       '2021-01-31T00:00:00.000000000', '2021-02-01T00:00:00.000000000',\n       '2021-02-02T00:00:00.000000000', '2021-02-03T00:00:00.000000000',\n       '2021-02-04T00:00:00.000000000', '2021-02-05T00:00:00.000000000',\n       '2021-02-06T00:00:00.000000000', '2021-02-07T00:00:00.000000000',\n       '2021-02-08T00:00:00.000000000', '2021-02-09T00:00:00.000000000',\n       '2021-02-10T00:00:00.000000000', '2021-02-11T00:00:00.000000000',\n       '2021-02-12T00:00:00.000000000', '2021-02-13T00:00:00.000000000',\n       '2021-02-14T00:00:00.000000000', '2021-02-15T00:00:00.000000000',\n       '2021-02-16T00:00:00.000000000', '2021-02-17T00:00:00.000000000',\n       '2021-02-18T00:00:00.000000000', '2021-02-19T00:00:00.000000000',\n       '2021-02-20T00:00:00.000000000', '2021-02-21T00:00:00.000000000',\n       '2021-02-22T00:00:00.000000000', '2021-02-23T00:00:00.000000000',\n       '2021-02-24T00:00:00.000000000', '2021-02-25T00:00:00.000000000',\n       '2021-02-26T00:00:00.000000000', '2021-02-27T00:00:00.000000000',\n       '2021-02-28T00:00:00.000000000', '2021-03-01T00:00:00.000000000',\n       '2021-03-02T00:00:00.000000000', '2021-03-03T00:00:00.000000000',\n       '2021-03-04T00:00:00.000000000', '2021-03-05T00:00:00.000000000',\n       '2021-03-06T00:00:00.000000000', '2021-03-07T00:00:00.000000000',\n       '2021-03-08T00:00:00.000000000', '2021-03-09T00:00:00.000000000',\n       '2021-03-10T00:00:00.000000000', '2021-03-11T00:00:00.000000000',\n       '2021-03-12T00:00:00.000000000', '2021-03-13T00:00:00.000000000',\n       '2021-03-14T00:00:00.000000000', '2021-03-15T00:00:00.000000000',\n       '2021-03-16T00:00:00.000000000', '2021-03-17T00:00:00.000000000',\n       '2021-03-18T00:00:00.000000000', '2021-03-19T00:00:00.000000000',\n       '2021-03-20T00:00:00.000000000', '2021-03-21T00:00:00.000000000',\n       '2021-03-22T00:00:00.000000000', '2021-03-23T00:00:00.000000000',\n       '2021-03-24T00:00:00.000000000', '2021-03-25T00:00:00.000000000',\n       '2021-03-26T00:00:00.000000000', '2021-03-27T00:00:00.000000000',\n       '2021-03-28T00:00:00.000000000', '2021-03-29T00:00:00.000000000',\n       '2021-03-30T00:00:00.000000000', '2021-03-31T00:00:00.000000000',\n       '2021-04-01T00:00:00.000000000', '2021-04-02T00:00:00.000000000',\n       '2021-04-03T00:00:00.000000000', '2021-04-04T00:00:00.000000000',\n       '2021-04-05T00:00:00.000000000', '2021-04-06T00:00:00.000000000',\n       '2021-04-07T00:00:00.000000000', '2021-04-08T00:00:00.000000000',\n       '2021-04-09T00:00:00.000000000', '2021-04-10T00:00:00.000000000',\n       '2021-04-11T00:00:00.000000000', '2021-04-12T00:00:00.000000000',\n       '2021-04-13T00:00:00.000000000', '2021-04-14T00:00:00.000000000',\n       '2021-04-15T00:00:00.000000000', '2021-04-16T00:00:00.000000000',\n       '2021-04-17T00:00:00.000000000', '2021-04-18T00:00:00.000000000',\n       '2021-04-19T00:00:00.000000000', '2021-04-20T00:00:00.000000000',\n       '2021-04-21T00:00:00.000000000', '2021-04-22T00:00:00.000000000',\n       '2021-04-23T00:00:00.000000000', '2021-04-24T00:00:00.000000000',\n       '2021-04-25T00:00:00.000000000', '2021-04-26T00:00:00.000000000',\n       '2021-04-27T00:00:00.000000000', '2021-04-28T00:00:00.000000000',\n       '2021-04-29T00:00:00.000000000', '2021-04-30T00:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (1)test(lat, lon, time)float640.776 0.7811 ... 0.1644 0.4596array([[[0.77603969, 0.78109427, 0.47463613, ..., 0.87721132,\n         0.74602999, 0.52795515],\n        [0.45447559, 0.06098814, 0.56153752, ..., 0.54317466,\n         0.16588401, 0.47182426],\n        [0.34680745, 0.56432993, 0.33087893, ..., 0.46754496,\n         0.77386586, 0.54263437],\n        ...,\n        [0.07420475, 0.0070979 , 0.14453391, ..., 0.38721994,\n         0.60021619, 0.02995067],\n        [0.19514364, 0.81407898, 0.63433033, ..., 0.20618559,\n         0.90066779, 0.44161434],\n        [0.18642075, 0.50003163, 0.99067054, ..., 0.08024937,\n         0.36738555, 0.10980183]],\n\n       [[0.70555665, 0.14284078, 0.70875054, ..., 0.57620035,\n         0.16385631, 0.72072702],\n        [0.92470363, 0.52236745, 0.57963961, ..., 0.64278929,\n         0.44062747, 0.62948897],\n        [0.60057287, 0.82735434, 0.25721172, ..., 0.43308672,\n         0.01142561, 0.66446529],\n...\n        [0.97625956, 0.05430192, 0.5298551 , ..., 0.12510365,\n         0.89511694, 0.83309839],\n        [0.00738604, 0.26324513, 0.62614711, ..., 0.44061988,\n         0.40261553, 0.61131219],\n        [0.63686144, 0.33371723, 0.81716691, ..., 0.38339975,\n         0.87549086, 0.56223801]],\n\n       [[0.62583546, 0.80383792, 0.04575515, ..., 0.57343556,\n         0.98141056, 0.38545278],\n        [0.02712301, 0.50806461, 0.80414313, ..., 0.00410264,\n         0.49060678, 0.86332988],\n        [0.84853947, 0.8671531 , 0.14139461, ..., 0.3875468 ,\n         0.92033547, 0.42666932],\n        ...,\n        [0.69560469, 0.58277231, 0.61229937, ..., 0.54120346,\n         0.72426412, 0.04719725],\n        [0.92599611, 0.47396361, 0.80866523, ..., 0.71887038,\n         0.03053566, 0.09969883],\n        [0.78287112, 0.77153977, 0.76741175, ..., 0.92923526,\n         0.1644041 , 0.45964236]]], shape=(40, 60, 120))Indexes: (3)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))timePandasIndexPandasIndex(DatetimeIndex(['2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04',\n               '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08',\n               '2021-01-09', '2021-01-10',\n               ...\n               '2021-04-21', '2021-04-22', '2021-04-23', '2021-04-24',\n               '2021-04-25', '2021-04-26', '2021-04-27', '2021-04-28',\n               '2021-04-29', '2021-04-30'],\n              dtype='datetime64[ns]', name='time', length=120, freq='D'))Attributes: (0)\n\n\n\n# 1 monthly interval\nda_monthly_mean = ds.test.resample(time=\"1MS\").mean()\n\n\ndef custom_agg_func(da: xr.DataArray) -> xr.DataArray:\n    # dummy operation - could by anything\n    return da.sum(dim=\"time\") / da.count(dim=\"time\")\n\n\nda_monthly_mean_custom = ds.test.resample(time=\"1MS\").apply(custom_agg_func)\n\n\nassert (da_monthly_mean_custom == da_monthly_mean).all()"
  },
  {
    "objectID": "code-snippets/xarray/04_resampling_xr_reproject.html",
    "href": "code-snippets/xarray/04_resampling_xr_reproject.html",
    "title": "Dask-backed (lazy) resampling",
    "section": "",
    "text": "import xarray as xr\nimport rioxarray\nfrom rasterio.enums import Resampling\nfrom odc.algo import xr_reproject\nfrom odc.geo.geobox import GeoBox as GeoBox_, BoundingBox\nfrom datacube.utils.geometry import GeoBox\nfrom affine import Affine\n\n\ndef webcam_to_01(snow_cover: xr.DataArray):\n    return xr.where(snow_cover == 2, 0, snow_cover)\n\n\nds_webcam = xr.open_zarr(\"./data/webcam_snow_cover.zarr\")\n\n\nds_webcam\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 160MB\nDimensions:      (time: 1, y: 4250, x: 4700)\nCoordinates:\n  * time         (time) datetime64[ns] 8B 2021-07-15\n  * x            (x) float64 38kB 6.563e+05 6.563e+05 ... 6.61e+05 6.61e+05\n  * y            (y) float64 34kB 5.213e+06 5.213e+06 ... 5.209e+06 5.209e+06\nData variables:\n    snow_cover   (time, y, x) float64 160MB dask.array<chunksize=(1, 1024, 1024), meta=np.ndarray>\n    spatial_ref  int64 8B ...xarray.DatasetDimensions:time: 1y: 4250x: 4700Coordinates: (3)time(time)datetime64[ns]2021-07-15array(['2021-07-15T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float646.563e+05 6.563e+05 ... 6.61e+05array([656320.5, 656321.5, 656322.5, ..., 661017.5, 661018.5, 661019.5],\n      shape=(4700,))y(y)float645.213e+06 5.213e+06 ... 5.209e+06array([5213489.5, 5213488.5, 5213487.5, ..., 5209242.5, 5209241.5, 5209240.5],\n      shape=(4250,))Data variables: (2)snow_cover(time, y, x)float64dask.array<chunksize=(1, 1024, 1024), meta=np.ndarray>AREA_OR_POINT :Areagrid_mapping :spatial_ref\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         152.40 MiB \n                         8.00 MiB \n                    \n                    \n                    \n                         Shape \n                         (1, 4250, 4700) \n                         (1, 1024, 1024) \n                    \n                    \n                         Dask graph \n                         25 chunks in 2 graph layers \n                    \n                    \n                         Data type \n                         float64 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n  \n  \n  \n\n  \n  \n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  4700\n  4250\n  1\n\n        \n    \nspatial_ref()int64...GeoTransform :656320.0 1.0 0.0 5213490.0 0.0 -1.0crs_wkt :PROJCS[\"ETRS89 / UTM zone 32N\",GEOGCS[\"ETRS89\",DATUM[\"European_Terrestrial_Reference_System_1989\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6258\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4258\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"25832\"]]false_easting :500000.0false_northing :0.0geographic_crs_name :ETRS89grid_mapping_name :transverse_mercatorhorizontal_datum_name :European Terrestrial Reference System 1989inverse_flattening :298.257222101latitude_of_projection_origin :0.0longitude_of_central_meridian :9.0longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichprojected_crs_name :ETRS89 / UTM zone 32Nreference_ellipsoid_name :GRS 1980scale_factor_at_central_meridian :0.9996semi_major_axis :6378137.0semi_minor_axis :6356752.314140356spatial_ref :PROJCS[\"ETRS89 / UTM zone 32N\",GEOGCS[\"ETRS89\",DATUM[\"European_Terrestrial_Reference_System_1989\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6258\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4258\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",9],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"25832\"]][1 values with dtype=int64]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2021-07-15'], dtype='datetime64[ns]', name='time', freq=None))xPandasIndexPandasIndex(Index([656320.5, 656321.5, 656322.5, 656323.5, 656324.5, 656325.5, 656326.5,\n       656327.5, 656328.5, 656329.5,\n       ...\n       661010.5, 661011.5, 661012.5, 661013.5, 661014.5, 661015.5, 661016.5,\n       661017.5, 661018.5, 661019.5],\n      dtype='float64', name='x', length=4700))yPandasIndexPandasIndex(Index([5213489.5, 5213488.5, 5213487.5, 5213486.5, 5213485.5, 5213484.5,\n       5213483.5, 5213482.5, 5213481.5, 5213480.5,\n       ...\n       5209249.5, 5209248.5, 5209247.5, 5209246.5, 5209245.5, 5209244.5,\n       5209243.5, 5209242.5, 5209241.5, 5209240.5],\n      dtype='float64', name='y', length=4250))Attributes: (0)\n\n\n\n\n\n\ndef xr_reproject(\n    src: DataArray | Dataset,\n    geobox: GeoBox,\n    resampling: str = \"nearest\",\n    chunks: Tuple[int, int] | None = None,\n    dst_nodata: NodataType | None = None,\n    **kwargs: Unknown\n) -> (DataArray | Dataset)\n\n\n\n\ngeobox: GeoBox is a datacube.utils.geometry not a odc.geo.geobox: this needs to be constructed first (see notes below)\nany src: DataArray | Dataset needs to have a .odc.geobox and .odc.crs attribute.\n\n\n\n\n\n\nxmin, xmax = 656320.0, 661020.0\nymax, ymin = 5213480.0, 5209240.0\n\n\nlower_res = 20 # target resolution in meters\n\n\n\n\n\nwidth = int((xmax - xmin) / lower_res)\nheight = int((ymax - ymin) / lower_res)\n\n\ngeobox = GeoBox(\n    width=width,\n    height=height,\n    affine=Affine(lower_res, 0.0, xmin, 0.0, lower_res * -1, ymax),\n    crs=\"epsg:25832\",\n)\n\n\n\n\n\nbbox = BoundingBox(left=xmin, top=ymax, bottom=ymin, right=xmax)\ngeobox_ = GeoBox_.from_bbox(bbox=bbox, crs=25832, resolution=lower_res)\ngeobox_2 = GeoBox(\n    width=geobox_.width, height=geobox_.height, affine=geobox_.affine, crs=\"epsg:25832\"\n)\n\n\ngeobox_2 = GeoBox(\n    width=geobox_.width, height=geobox_.height, affine=geobox_.affine, crs=\"epsg:25832\"\n)\n\n\nassert geobox == geobox_2"
  },
  {
    "objectID": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-computation-on-dataset---this-leads-to-the-spatial-ref-getting-lost",
    "href": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-computation-on-dataset---this-leads-to-the-spatial-ref-getting-lost",
    "title": "Dask-backed (lazy) resampling",
    "section": "Perform computation on dataset - this leads to the spatial ref getting lost…",
    "text": "Perform computation on dataset - this leads to the spatial ref getting lost…\n\n# snow cover as 0 and 1\nsnow_cover = webcam_to_01(ds_webcam.snow_cover)"
  },
  {
    "objectID": "code-snippets/xarray/04_resampling_xr_reproject.html#setting-crs-for-spatial_ref",
    "href": "code-snippets/xarray/04_resampling_xr_reproject.html#setting-crs-for-spatial_ref",
    "title": "Dask-backed (lazy) resampling",
    "section": "Setting crs for spatial_ref",
    "text": "Setting crs for spatial_ref\n\nif snow_cover.odc.geobox.crs is None:\n    print(\"Dataset's missing the crs\")\n\nDataset's missing the crs\n\n\n\n# this makes .spatial_ref and .geobox available (actually .geobox is added by datacube)\n# (not sufficient anymore)\n# snow_cover.rio.write_crs(\"epsg:25832\", inplace=True)\n\n\n# (not sufficient anymore)\n# snow_cover[\"spatial_ref\"] = ds_webcam.spatial_ref\n\n\nsnow_cover = snow_cover.odc.assign_crs(25832)\n\n\nassert snow_cover.odc.crs"
  },
  {
    "objectID": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-actual-resampling",
    "href": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-actual-resampling",
    "title": "Dask-backed (lazy) resampling",
    "section": "Perform actual resampling",
    "text": "Perform actual resampling\n\nsnow_cover_downsampled = xr_reproject(snow_cover, geobox, resampling=Resampling.mode)\n\n\nsnow_cover_downsampled.plot()\n\n<matplotlib.collections.QuadMesh at 0x7166d43f1010>"
  },
  {
    "objectID": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-computation-on-dataset---this-often-leads-to-some-part-of-the-spatial-ref-getting-lost",
    "href": "code-snippets/xarray/04_resampling_xr_reproject.html#perform-computation-on-dataset---this-often-leads-to-some-part-of-the-spatial-ref-getting-lost",
    "title": "Dask-backed (lazy) resampling",
    "section": "Perform computation on dataset - this often leads to some part of the spatial ref getting lost…",
    "text": "Perform computation on dataset - this often leads to some part of the spatial ref getting lost…\n\n# snow cover as 0 and 1\nsnow_cover = webcam_to_01(ds_webcam.snow_cover)"
  },
  {
    "objectID": "code-snippets/xarray/01_rf_predict_map_blocks.html",
    "href": "code-snippets/xarray/01_rf_predict_map_blocks.html",
    "title": "ds.map_blocks(…)",
    "section": "",
    "text": "This is the preferred version for chunk-wise processing of an xarray.Dataset\n\nimport dask.array as da\nimport xarray as xr\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier as RF\n\n\nn_features = 50\n\n\nn_samples = 1000\n# random training data\nX_train = da.random.random((n_samples, n_features))\ny_train = da.random.randint(0, 2, n_samples)\n\nrf = RF(random_state=42, n_estimators=50, n_jobs=-1)\nrf.fit(X_train, y_train)\n\n\n# random training data\nlat = np.arange(4000)\nlon = np.arange(6000)\ntime = np.arange(n_features)\ndata = da.random.random((lat.size, lon.size, time.size))\n\n\nds = xr.DataArray(\n    data, coords=[lat, lon, time], dims=[\"lat\", \"lon\", \"time\"], name=\"test\"\n).to_dataset()\n\n\ndef generic_func(ds: xr.Dataset):\n    ds_stacked = ds.stack(ml=(\"lat\", \"lon\")).transpose(\"ml\", \"time\")\n\n    # predict on input data\n    X = ds_stacked.test.data\n    y_hat_1d = rf.predict(X)\n    y_hat_2d = y_hat_1d.reshape((ds.lat.size, ds.lon.size))\n\n    data_out = ds.isel(time=[0]).squeeze().copy(deep=True)\n    data_out.test.data = y_hat_2d\n\n    return data_out\n\n\nds_pred = ds.map_blocks(generic_func, template=ds.isel(time=[0]).squeeze())\n\n\nds_pred\n\n\nds_pred = ds_pred.compute()"
  },
  {
    "objectID": "code-snippets/xarray/00_rf_predict_map_blocks.html",
    "href": "code-snippets/xarray/00_rf_predict_map_blocks.html",
    "title": "ds.map_blocks(…)",
    "section": "",
    "text": "This is the preferred version for chunk-wise processing of an xarray.Dataset\n\nimport dask.array as da\nimport xarray as xr\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier as RF\n\n\nn_features = 50\n\n\nn_samples = 1000\n# random training data\nX_train = da.random.random((n_samples, n_features))\ny_train = da.random.randint(0, 2, n_samples)\n\nrf = RF(random_state=42, n_estimators=50, n_jobs=-1)\nrf.fit(X_train, y_train)\n\n\n# random training data\nlat = np.arange(4000)\nlon = np.arange(6000)\ntime = np.arange(n_features)\ndata = da.random.random((lat.size, lon.size, time.size))\n\n\nds = xr.DataArray(\n    data, coords=[lat, lon, time], dims=[\"lat\", \"lon\", \"time\"], name=\"test\"\n).to_dataset()\n\n\ndef generic_func(ds: xr.Dataset):\n    ds_stacked = ds.stack(ml=(\"lat\", \"lon\")).transpose(\"ml\", \"time\")\n\n    # predict on input data\n    X = ds_stacked.test.data\n    y_hat_1d = rf.predict(X)\n    y_hat_2d = y_hat_1d.reshape((ds.lat.size, ds.lon.size))\n\n    data_out = ds.isel(time=[0]).squeeze().copy(deep=True)\n    data_out.test.data = y_hat_2d\n\n    return data_out\n\n\nds_pred = ds.map_blocks(generic_func, template=ds.isel(time=[0]).squeeze())\n\n\nds_pred\n\n\nds_pred = ds_pred.compute()"
  },
  {
    "objectID": "code-snippets/xarray/01_rf_predict_apply_ufunc.html",
    "href": "code-snippets/xarray/01_rf_predict_apply_ufunc.html",
    "title": "xr.apply_ufunc(…)",
    "section": "",
    "text": "Note: ds.map_blocks() likely is a lot faster compared to this version! This is really only for demonstrative purpose.\n\nimport dask.array as da\nimport xarray as xr\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier as RF\n\n\nn_features = 12\n\n\nn_samples = 1000\n# random training data\nX_train = da.random.random((n_samples,n_features))\ny_train = da.random.randint(0, 2, n_samples)\n\nrf = RF(random_state = 42, n_estimators=50, n_jobs=-1)\nrf.fit(X_train, y_train)\n\nRandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42) \n\n\n\n# random training data\n# keep size reasonably small\nlat = np.arange(40)\nlon = np.arange(60)\ntime = np.arange(n_features)\ndata = da.random.random((lat.size,lon.size, time.size))\n\n\nds = xr.DataArray(\n    data,\n    coords=[lat, lon, time],\n    dims=[\"lat\", \"lon\", \"time\"],\n    name=\"test\",\n).to_dataset()\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 231kB\nDimensions:  (lat: 40, lon: 60, time: 12)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\n  * time     (time) int64 96B 0 1 2 3 4 5 6 7 8 9 10 11\nData variables:\n    test     (lat, lon, time) float64 230kB dask.array<chunksize=(40, 60, 12), meta=np.ndarray>xarray.DatasetDimensions:lat: 40lon: 60time: 12Coordinates: (3)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])time(time)int640 1 2 3 4 5 6 7 8 9 10 11array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])Data variables: (1)test(lat, lon, time)float64dask.array<chunksize=(40, 60, 12), meta=np.ndarray>\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         225.00 kiB \n                         225.00 kiB \n                    \n                    \n                    \n                         Shape \n                         (40, 60, 12) \n                         (40, 60, 12) \n                    \n                    \n                         Dask graph \n                         1 chunks in 1 graph layer \n                    \n                    \n                         Data type \n                         float64 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  12\n  60\n  40\n\n        \n    \nIndexes: (3)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))timePandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype='int64', name='time'))Attributes: (0)\n\n\n\ndef generic_func(arr):\n    return rf.predict(arr.reshape(1, -1))\n\n\nds_ag = xr.apply_ufunc(\n    generic_func,\n    ds,\n    input_core_dims=[[\"time\"]],\n    dask=\"parallelized\",\n    output_dtypes=np.float32,\n    vectorize=True,\n    dask_gufunc_kwargs={\"allow_rechunk\": True},\n)\n\n\nds_ag\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 10kB\nDimensions:  (lat: 40, lon: 60)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\nData variables:\n    test     (lat, lon) float32 10kB dask.array<chunksize=(40, 60), meta=np.ndarray>xarray.DatasetDimensions:lat: 40lon: 60Coordinates: (2)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])Data variables: (1)test(lat, lon)float32dask.array<chunksize=(40, 60), meta=np.ndarray>\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         9.38 kiB \n                         9.38 kiB \n                    \n                    \n                    \n                         Shape \n                         (40, 60) \n                         (40, 60) \n                    \n                    \n                         Dask graph \n                         1 chunks in 4 graph layers \n                    \n                    \n                         Data type \n                         float32 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  60\n  40\n\n        \n    \nIndexes: (2)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))Attributes: (0)\n\n\n\nds_ag.compute()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset> Size: 10kB\nDimensions:  (lat: 40, lon: 60)\nCoordinates:\n  * lat      (lat) int64 320B 0 1 2 3 4 5 6 7 8 9 ... 31 32 33 34 35 36 37 38 39\n  * lon      (lon) int64 480B 0 1 2 3 4 5 6 7 8 9 ... 51 52 53 54 55 56 57 58 59\nData variables:\n    test     (lat, lon) float32 10kB 0.0 1.0 1.0 0.0 0.0 ... 1.0 1.0 1.0 1.0 1.0xarray.DatasetDimensions:lat: 40lon: 60Coordinates: (2)lat(lat)int640 1 2 3 4 5 6 ... 34 35 36 37 38 39array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39])lon(lon)int640 1 2 3 4 5 6 ... 54 55 56 57 58 59array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59])Data variables: (1)test(lat, lon)float320.0 1.0 1.0 0.0 ... 1.0 1.0 1.0 1.0array([[0., 1., 1., ..., 1., 0., 1.],\n       [1., 0., 0., ..., 1., 0., 0.],\n       [0., 1., 1., ..., 0., 1., 0.],\n       ...,\n       [0., 0., 1., ..., 0., 1., 1.],\n       [1., 0., 0., ..., 1., 1., 1.],\n       [0., 0., 0., ..., 1., 1., 1.]], shape=(40, 60), dtype=float32)Indexes: (2)latPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39],\n      dtype='int64', name='lat'))lonPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59],\n      dtype='int64', name='lon'))Attributes: (0)"
  },
  {
    "objectID": "code-snippets/joblib/00_parallel_everything.html",
    "href": "code-snippets/joblib/00_parallel_everything.html",
    "title": "Multithreading and -processing with joblib",
    "section": "",
    "text": "from joblib import Parallel, delayed\n\nCreate a function to be executed in parallel:\n\ndef my_embarassingly_parallel_job(arg):\n    # perform work...\n    return\n\nUses the default “loky” backend for process based parallelism:\n\nresults = Parallel(n_jobs=2)(\n    delayed(my_embarassingly_parallel_job)(i) for i in range(10)\n)\n\nThread-based parallelism:\n\nresults = Parallel(n_jobs=2, prefer=\"threads\")(\n    delayed(my_embarassingly_parallel_job)(i) for i in range(10)\n)"
  },
  {
    "objectID": "code-snippets/requests/00_get_request.html",
    "href": "code-snippets/requests/00_get_request.html",
    "title": "requests module",
    "section": "",
    "text": "import requests\n\nurl = \"....\"\n\nr = requests.get(url)\n\n# retrieve status code\nr.status_code \n\n# retrieve json formatted response\nr.json()\n\n# write non-binary output\nwith (\"out-file.txt\", \"w\") as fobj:\n    fobj.write(r.content)\n\n\n# write binary output (e.g., for zip-files and other binary formats)\nwith (\"out-file\", \"wb\") as fobj:\n    fobj.write(r.content)\nRecursive request in case of non-successful return code:\n\nurl = \"....\"\n\ndef request_until_success(url):\n    r = requests.get(url)\n\n    if r. status_code != 200:\n        # possibly delay renewed requests here ...\n\n        return request_until_success(url)\n\n    return r"
  }
]